{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTYAgNgr7T+wKZjh7Cno+2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hot-KimChi/virtual_try_on/blob/main/Virtual_Try_On.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DeepFashion Try-On\n",
        "\n",
        "Towards Photo-Realistic Virtual Try-On by Adaptively Generating↔Preserving Image Content, CVPR'20.\n",
        "\n",
        "![](https://github.com/switchablenorms/DeepFashion_Try_On/raw/master/images/tryon.png)\n",
        "\n",
        "## For inferencing ACGPN!\n",
        "\n",
        "ACGPN repo: https://github.com/switchablenorms/DeepFashion_Try_On\n",
        "\n",
        "This notebook is hard coded for inferencing one image at a time.\n",
        "\n",
        "Notebook by [Levin Dabhi](https://levindabhi.github.io/)\n",
        "\n",
        "```\n",
        "author = {Yang, Han and Zhang, Ruimao and Guo, Xiaobao and Liu, Wei and Zuo, Wangmeng and Luo, Ping},\n",
        "title = {Towards Photo-Realistic Virtual Try-On by Adaptively Generating-Preserving Image Content},\n",
        "booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
        "month = {June},\n",
        "year = {2020}\n",
        "}\n",
        "\n",
        "@inproceedings{ge2021disentangled,\n",
        "  title={Disentangled Cycle Consistency for Highly-realistic Virtual Try-On},\n",
        "  author={Ge, Chongjian and Song, Yibing and Ge, Yuying and Yang, Han and Liu, Wei and Luo, Ping},\n",
        "  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n",
        "  pages={16928--16937},\n",
        "  year={2021}\n",
        "}\n",
        "\n",
        "@inproceedings{yang2022full,\n",
        "title = {Full-Range Virtual Try-On With Recurrent Tri-Level Transform},\n",
        "author = {Yang, Han and Yu, Xinrui and Liu, Ziwei},\n",
        "booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n",
        "pages = {3460--3469}\n",
        "year = {2022}\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "DNNgqvTLSaUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ACGPN\n",
        "\n",
        "- Original: https://github.com/levindabhi/ACGPN.git\n",
        "- Modified: https://github.com/kairess/ACGPN.git"
      ],
      "metadata": {
        "id": "tVvTfepeSiQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kairess/ACGPN.git\n",
        "%cd ACGPN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLH1i81gUErB",
        "outputId": "1f46af76-d8a7-4d4d-bfaa-1c40bfc09d4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ACGPN'...\n",
            "remote: Enumerating objects: 165, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 165 (delta 21), reused 19 (delta 18), pack-reused 141\u001b[K\n",
            "Receiving objects: 100% (165/165), 303.15 KiB | 3.03 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "/content/ACGPN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --no-cache-dir gdown --pre -qq\n",
        "!pip install ninja -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1Fq0cTiT-Cd",
        "outputId": "b186dded-44b6-49d4-d0c3-fe397d2befe1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/146.0 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xLwJJ4dESVeC"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import IPython\n",
        "import gdown\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from predict_pose import generate_pose_keypoints"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir Data_preprocessing/test_color\n",
        "!mkdir Data_preprocessing/test_colormask\n",
        "!mkdir Data_preprocessing/test_edge\n",
        "!mkdir Data_preprocessing/test_img\n",
        "!mkdir Data_preprocessing/test_label\n",
        "!mkdir Data_preprocessing/test_mask\n",
        "!mkdir Data_preprocessing/test_pose\n",
        "!mkdir inputs\n",
        "!mkdir inputs/img\n",
        "!mkdir inputs/cloth"
      ],
      "metadata": {
        "id": "TPjWI6YkVCn9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/levindabhi/Self-Correction-Human-Parsing-for-ACGPN.git\n",
        "!git clone https://github.com/levindabhi/U-2-Net.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnIS96NJWEtV",
        "outputId": "5af8b9e6-7dc4-45c5-ab6e-21eb94ddaf17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Self-Correction-Human-Parsing-for-ACGPN'...\n",
            "remote: Enumerating objects: 769, done.\u001b[K\n",
            "remote: Counting objects: 100% (769/769), done.\u001b[K\n",
            "remote: Compressing objects: 100% (579/579), done.\u001b[K\n",
            "remote: Total 769 (delta 188), reused 720 (delta 179), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (769/769), 3.80 MiB | 18.61 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n",
            "Cloning into 'U-2-Net'...\n",
            "remote: Enumerating objects: 822, done.\u001b[K\n",
            "remote: Total 822 (delta 0), reused 0 (delta 0), pack-reused 822\u001b[K\n",
            "Receiving objects: 100% (822/822), 30.72 MiB | 38.27 MiB/s, done.\n",
            "Resolving deltas: 100% (379/379), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 사전학습 모델 다운로드"
      ],
      "metadata": {
        "id": "Bq7g6cEoWuAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 포즈 예측 모델: google drive에서 모델 다운로드"
      ],
      "metadata": {
        "id": "yWmIHBErW5FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko -O pose/pose_iter_440000.caffemodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s0t9IJGYEYV",
        "outputId": "9476b897-a9ef-44bc-e755-26ac64692313"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hOHMFHEjhoJuLEQY0Ndurn5hfiA9mwko\n",
            "To: /content/ACGPN/pose/pose_iter_440000.caffemodel\n",
            "100% 209M/209M [00:03<00:00, 65.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 휴먼 세그멘테이션 마스크 생성 모델"
      ],
      "metadata": {
        "id": "pdzjDB2AXvpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download('https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH', 'lip_final.pth', quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "2JjeKsUnXxHP",
        "outputId": "e3232e88-f650-45eb-dd56-520e89836f2b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH\n",
            "To: /content/ACGPN/lip_final.pth\n",
            "100%|██████████| 267M/267M [00:14<00:00, 17.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lip_final.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### U2Net 모델\n",
        "\n",
        "옷 마스크 추출 모델"
      ],
      "metadata": {
        "id": "LWI9fsOHXuef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd U-2-Net\n",
        "!mkdir saved_models\n",
        "!mkdir saved_models/u2net\n",
        "!mkdir saved_models/u2netp\n",
        "\n",
        "!gdown 1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy -O saved_models/u2netp/u2netp.pth\n",
        "!gdown 1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ -O saved_models/u2net/u2net.pth\n",
        "\n",
        "import u2net_load\n",
        "import u2net_run\n",
        "\n",
        "u2net = u2net_load.model(model_name='u2netp')\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wphIfJguXnYL",
        "outputId": "6aa18422-7517-448b-bfb5-d8cec190d7a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ACGPN/U-2-Net\n",
            "mkdir: cannot create directory ‘saved_models’: File exists\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy\n",
            "To: /content/ACGPN/U-2-Net/saved_models/u2netp/u2netp.pth\n",
            "100% 4.68M/4.68M [00:00<00:00, 132MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ\n",
            "To: /content/ACGPN/U-2-Net/saved_models/u2net/u2net.pth\n",
            "100% 176M/176M [00:01<00:00, 136MB/s]\n",
            "...load U2NEP---4.7 MB\n",
            "/content/ACGPN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ACGPN 모델"
      ],
      "metadata": {
        "id": "7qr7PU46Y7Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints\n",
        "\n",
        "gdown.download('https://drive.google.com/uc?id=1UWT6esQIU_d4tUm8cjxDKMhB8joQbrFx', output='checkpoints/ACGPN_checkpoints.zip', quiet=False)\n",
        "\n",
        "!unzip checkpoints/ACGPN_checkpoints.zip -d checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvtoFRi_Y6wZ",
        "outputId": "f0a0e0d8-3317-4572-b1af-fb704d2483bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘checkpoints’: File exists\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UWT6esQIU_d4tUm8cjxDKMhB8joQbrFx\n",
            "To: /content/ACGPN/checkpoints/ACGPN_checkpoints.zip\n",
            "100%|██████████| 524M/524M [00:03<00:00, 148MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  checkpoints/ACGPN_checkpoints.zip\n",
            "replace checkpoints/label2city/latest_net_G.pth? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace checkpoints/label2city/latest_net_G.pth? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: checkpoints/label2city/latest_net_G.pth  \n",
            "  inflating: checkpoints/label2city/latest_net_G1.pth  \n",
            "  inflating: checkpoints/label2city/latest_net_G2.pth  \n",
            "  inflating: checkpoints/label2city/latest_net_U.pth  \n",
            "  inflating: checkpoints/label2city/opt.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VITON 데이터셋\n",
        "\n",
        "https://drive.google.com/uc?id=1tE7hcVFm8Td8kRh5iYRBSDFdvZIkbUIR\n",
        "\n",
        "## AI허브 패션 데이터셋\n",
        "\n",
        "https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=78\n",
        "\n",
        "![](https://aihub.or.kr/web-nas/aihub21/files/public/inline-images/65_%ED%8C%A8%EC%85%98%EC%83%81%ED%92%88%EB%B0%8F%EC%B0%A9%EC%9A%A9%EC%98%81%EC%83%81_%EB%8C%80%ED%91%9C%EB%8F%84.PNG)"
      ],
      "metadata": {
        "id": "FQCLYRuPZHzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(os.listdir('inputs/cloth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QarbfTarZWA3",
        "outputId": "99bea35b-2a7c-42de-f5b6-6bb9f3591645"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}